%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% "ModernCV" CV and Cover Letter
% LaTeX Template
% Version 1.1 (9/12/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Xavier Danaux (xdanaux@gmail.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
% PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[12pt,a4paper,sans]{moderncv}

\moderncvstyle{classic}
\moderncvcolor{blue}

% Added font packages to provide more font shapes/sizes and reduce substitution warnings
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\usepackage[scale=0.90]{geometry}

\newcommand{\techstack}[1]{\textit{Stack:} #1}
\newcommand{\entryspacing}{\vspace{0.2cm}}

%----------------------------------------------------------------------------------------
% NAME AND CONTACT INFORMATION SECTION
%----------------------------------------------------------------------------------------

\firstname{\textcolor{color1}{Thomas}}
\familyname{\textcolor{color1}{Chauvet}}

\address{Geneva, Switzerland}{C permit}{}
\homepage{thomas.chauvet@protonmail.com}
\social[linkedin]{www.linkedin.com/in/thomaschauvet/}{}
\social[github]{www.github.com/thomas-chauvet/}

%----------------------------------------------------------------------------------------

\begin{document}

\makecvtitle

\vspace{-1.0cm}

\begin{center}
    \Large{\textbf{\textcolor{color1}{Senior Data Engineer}}} - 10+ years experience
\end{center}

\textcolor{color2}{Senior Data Engineer with 10+ years experience building end-to-end data platforms}

\vspace{0.3cm}

%----------------------------------------------------------------------------------------
% EXPERIENCE SECTION
%----------------------------------------------------------------------------------------

\section{Experience}

\cventry{Jan. 2024 \\--\\ Present}{Senior Data Engineer}{\textsc{Dyneo} (Thermal network optimization startup)}{Geneva, Switzerland}{}{
    \begin{itemize}
        \item Architected and maintain complete data lakehouse platform (Delta Lake on S3-compatible storage) with multi-engine query support (DuckDB, Polars).
        \item Built self-service capabilities enabling data consumers to access curated datasets through lightweight catalog and query interfaces.
        \item Designed and deployed data ingestion pipelines with Airflow on Kubernetes for batch processing and transformation.
        \item Implemented Infrastructure as Code (Terraform) for entire cloud stack; automated CI/CD pipelines (GitHub Actions) for deployments.
        \item Established custom data quality framework (API and alerting) and observability (metrics, logging) ensuring reliability.
    \end{itemize}
    \techstack{Python, SQL, Delta Lake, Airflow, Kubernetes, DuckDB, Polars, PostgreSQL, S3, Terraform, GitHub Actions}
}

\entryspacing
\cventry{Jun. 2022 \\--\\ Dec. 2023}{Senior Data Engineer}{\textsc{E-nno} (Energy efficiency startup)}{Geneva, Switzerland}{}{
    \begin{itemize}
        \item Designed and maintained entire data platform architecture combining streaming (Kafka ecosystem) and batch processing (Airflow on Kubernetes).
        \item Built real-time data ingestion pipelines using Kafka, Kafka Connect, and Faust for IoT telemetry processing and enrichment.
        \item Implemented high-performance PostgreSQL databases with optimized data models for analytics workloads and dashboard serving.
        \item Established CI/CD pipelines (GitHub Actions) for platform components.
    \end{itemize}
    \techstack{Python, Kafka, Kakfa-Connect, Faust, PostgreSQL, Airflow, Kubernetes, GitHub Actions}
}

\entryspacing

\cventry{Sep. 2021 \\--\\ May 2022}{Machine Learning Engineer}{\textsc{Rocket Software}}{Geneva, Switzerland}{}{
    \begin{itemize}
        \item Led delivery of a time-series forecasting platform from discovery to on-premise deployment.
        \item Gathered / refined business requirements and translated them into model, data and deployment design.
        \item Evaluated multiple ML approaches; standardized experiment tracking with MLflow.
        \item Engineered robust extraction / transformation pipelines and packaging for secure offline installation.
    \end{itemize}
    \techstack{Python, Elasticsearch, MLflow, Docker, Jenkins}
}

\entryspacing

\cventry{May 2019 \\--\\ Jul. 2021}{Artificial Intelligence Engineer}{\textsc{International Committee of the Red Cross (ICRC)}}{Geneva, Switzerland}{}{
    \begin{itemize}
        \item Architected distributed search and data platform over segregated sources with strict security and governance requirements.
        \item Built complete data ingestion and streaming pipelines using Kafka and Faust; implemented Elasticsearch for high-performance querying.
        \item Developed backend services (FastAPI) and automated deployments with Docker and Ansible ensuring compliance and data security.
    \end{itemize}
    \techstack{Python (Faust, FastAPI), Kafka, Elasticsearch, Docker, Ansible}
}

\entryspacing

\cventry{Aug. 2017 \\--\\ Mar. 2019}{Data Scientist / Engineer}{\textsc{Bleckwen} (FinTech startup)}{Paris, France}{}{
    \begin{itemize}
        \item Co-architected from scratch a real-time streaming platform using Apache Flink and Kafka for fraud detection at scale.
        \item Designed and implemented streaming data pipelines (Scala/Flink) processing high-volume transactions with sub-second latency requirements.
        \item Deployed containerized platform components (Docker) with hot model deployment capabilities in production streaming pipeline.
    \end{itemize}
    \techstack{Scala, Apache Flink, Kafka, Python (Pandas, scikit-learn), Docker}
}

\entryspacing

\cventry{Feb. 2015 \\--\\ Jul. 2017}{Data Scientist}{\textsc{Deepki} (Energy efficiency startup)}{Paris, France}{}{
    \begin{itemize}
        \item Collected, normalized and unified heterogeneous data (invoices, telemetry, asset and activity data).
        \item Applied clustering and supervised learning for consumption modeling, anomaly detection and renovation impact simulation.
        \item Early employee contributing to SaaS platform foundations (data model, analytics features, recommendation / alert logic).
        \item Mentored student projects and interns.
    \end{itemize}
    \techstack{Python (scikit-learn, Pandas, Flask), R (tidyverse: dplyr, tidyr, ggplot2, Shiny)}
}

%----------------------------------------------------------------------------------------
% SKILLS SECTION
%----------------------------------------------------------------------------------------

\section{Technical Skills}

\cvitem{Programming}{Python, SQL, Bash, R, Scala}
\cvitem{Streaming}{Kafka, Kafka-Connect, Flink, Faust, Bytewax}
\cvitem{Processing}{SQL, DuckDB, Polars, Pandas}
\cvitem{Orchestration}{Airflow}
\cvitem{Databases}{PostgreSQL, TimescaleDB, Elasticsearch}
\cvitem{Infrastructure}{Docker, Kubernetes, Terraform (IaC), GitHub Actions}
\cvitem{Monitoring}{Prometheus, alertmanager}
\cvitem{Dashboarding}{Grafana}

%----------------------------------------------------------------------------------------
% EDUCATION SECTION
%----------------------------------------------------------------------------------------

\section{Education}

\cventry{2012 -- 2015}{INSA Toulouse}{Toulouse, France}{French Graduate Engineering School}{}{Engineering degree (M.Sc.) in computational and mathematical engineering; specialization in statistical methods and data science.}

\cventry{2009 -- 2012}{INSA Lyon}{Lyon, France}{}{}{Intensive preparatory cycle in Mathematics, Physics, Mechanics, Chemistry.}

%----------------------------------------------------------------------------------------
% LANGUAGES SECTION
%----------------------------------------------------------------------------------------

\section{Languages}
\cvitem{}{Native \textbf{French}. Fluent \textbf{English}}

\end{document}
